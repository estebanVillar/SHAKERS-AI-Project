# Implementation: The User Profile and Interest Vector

## 1. Overview: The Foundation of Personalization
To provide personalized recommendations, the system must first understand the user. This is achieved by building a user profile that dynamically captures their interests during a chat session. This profile serves as the "brain" for the recommendation engine, enabling it to move beyond generic suggestions to offer content tailored specifically to the user's line of inquiry.

All profile data for a session is persisted in the `user_profiles.json` file. To ensure data integrity in a multi-threaded server environment, all write operations to this file are protected by a `threading.Lock` (`file_lock` in `main.py`).

---

## 2. Structure of the User Profile
Each user is identified by a unique `user_id` generated by the Streamlit frontend. Their corresponding profile in the JSON file is an object with three key components:

*   **`query_history`**: A chronological log of every raw query the user has submitted, complete with timestamps. This serves as a raw audit trail of the user's journey.

*   **`inferred_interests`**: A list of unique document `topics` that the user has already been exposed to. This list is populated from the `sources` that are retrieved by the RAG chain in response to a user's query.
    *   **Why this is crucial:** This list is the system's "memory" of what the user has already seen. The recommendation logic uses this list to prioritize suggesting **new, unconsulted documents**, directly fulfilling the case study requirement to help users explore a wider range of topics.

*   **`profile_vector`**: This is the most critical component for personalization. It is a single vector (a list of 768 floating-point numbers) that numerically represents the user's aggregated interests. It is their "center of gravity" in the concept space.

---

## 3. The Evolving Profile Vector: A Moving Average of Interests
The `profile_vector` is not static; it evolves with every valid query the user makes, becoming a more accurate representation of their interests over time. This logic resides within the `handle_query` function in `main.py` and is executed after every RAG response is generated.

### 3.1. Step 1: Embed the Current Query
The user's latest query is converted into a vector using the same `models/embedding-001` model that was used for the documents.

### 3.2. Step 2: Average with Past Interests
*   **If this is the user's first query:** Their new query vector becomes their initial `profile_vector`.
*   **If the user already has a `profile_vector`:** The system takes the existing vector and averages it with the new query's vector using `numpy.mean`. This subtly shifts the user's interest vector in the direction of their latest query.

### 3.3. Step 3: Persist the Update
The newly calculated `profile_vector` is saved back into the `user_profiles.json` file, ready to be used by the next call to the `/api/recommendations` endpoint.

---

## 4. Design Rationale: "Why This Approach?"
This "moving average of embeddings" method was chosen as a computationally efficient yet highly effective way to model user interest.

*   **Efficiency:** It avoids the need for complex models or retraining. The profile update is a simple, sub-second mathematical operation (`numpy.mean`), making it perfectly suited for a real-time web application.
*   **Effectiveness:** It naturally adapts to a user's shifting focus during a single conversation. If a user starts asking about RAG and then pivots to questions about the frontend, their interest vector will fluidly follow them, ensuring recommendations remain relevant to their current train of thought.