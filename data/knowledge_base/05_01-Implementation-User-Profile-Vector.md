# Implementation: The User Profile and Dynamic Interest Vector

## 1. Overview: The Foundation of Personalization
To fulfill the case study's requirement of providing proactive, personalized recommendations, the system must first build an understanding of the user. This is achieved by creating and dynamically updating a user profile for each chat session. This profile serves as the "brain" for the recommendation engine, enabling it to move beyond generic or simply popular suggestions to offer content tailored specifically to the user's evolving line of inquiry.

All user profile data for active sessions is persisted in the `user_profiles.json` file. To ensure data integrity in a multi-threaded server environment (where multiple users could be interacting simultaneously), all read and write operations to this file are protected by a `threading.Lock` (`file_lock` in `utils.py`), preventing race conditions.

---

## 2. Structure of the User Profile
Each user is identified by a unique `user_id` generated by the Streamlit frontend upon their first visit. Their corresponding profile in the `user_profiles.json` file is a JSON object with three key components:

*   **`query_history`**: A chronological log of every raw query the user has submitted, complete with a UTC timestamp. This serves as a raw audit trail of the user's conversational journey and is used by our evaluation script to simulate user behavior.

*   **`inferred_interests`**: A list of unique document `topics` (e.g., `04_01-Implementation-Ingestion-and-Indexing`) that the user has already been exposed to. This list is populated from the `sources` that are retrieved and cited by the RAG chain in response to a user's query.
    *   **Why this is crucial:** This list acts as the system's "memory" of what the user has already seen. The recommendation logic uses this list to heavily prioritize suggesting **new, unconsulted documents**, directly fulfilling the case study requirement to help users explore a wider range of topics and gain a fuller understanding of the project.

*   **`profile_vector`**: This is the most critical component for personalization. It is a single vector (a list of 768 floating-point numbers) that numerically represents the user's aggregated or "average" interests. It is their "center of gravity" in the conceptual space defined by our embedding model.

---

## 3. The Evolving Profile Vector: A Moving Average of Interests
The `profile_vector` is not static; it evolves with every valid query the user makes, becoming a more accurate representation of their interests over time. This update logic resides within the `_update_user_profile` function in `main.py` and is executed immediately after a successful RAG response is generated.

The process is as follows:

### 3.1. Step 1: Embed the Current Query
The user's latest query (e.g., "How do you handle conversational context?") is converted into a 768-dimension vector using the same `models/embedding-001` model that was used for the documents. This gives us a numerical representation of the user's most recent interest.

### 3.2. Step 2: Average with Past Interests
*   **For the user's first query:** Their new query vector simply becomes their initial `profile_vector`.
*   **For subsequent queries:** The system updates the vector using a **weighted moving average**. It takes the existing `profile_vector` and averages it with the new query's vector. In our implementation, we use an 80/20 weighting:
    `new_vector = (existing_vector * 0.8) + (new_query_vector * 0.2)`
    This calculation, performed efficiently using `numpy`, subtly shifts the user's interest vector in the direction of their latest query.

### 3.3. Step 3: Persist the Update
The newly calculated `profile_vector` is saved back into the `user_profiles.json` file, ready to be used by the very next call to the `/api/recommendations` endpoint.

---

## 4. Design Rationale: Why This "Moving Average" Approach?
This "moving average of embeddings" method was deliberately chosen as a computationally efficient yet highly effective way to model evolving user interest in real-time.

*   **Simplicity and Efficiency:** It avoids the need for complex models, retraining, or heavy computation. The profile update is a simple, sub-second vector arithmetic operation (`numpy.add` and `numpy.multiply`), making it perfectly suited for a responsive web application. There's no performance bottleneck.
*   **Adaptability and Recency Bias:** The weighted average approach naturally adapts to a user's shifting focus during a single conversation. If a user starts by asking about RAG, then pivots to questions about the frontend, their interest vector will fluidly follow them. The 80/20 weighting gives more importance to recent queries, ensuring recommendations remain relevant to their current train of thought rather than being overly influenced by questions they asked long ago. This makes the personalization feel current and dynamic.